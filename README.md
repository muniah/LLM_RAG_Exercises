# LLM + RAG Playground

A hands-on playground for experimenting with **Large Language Models (LLMs)** and **Retrieval-Augmented Generation (RAG)** pipelines using open-source tools, vector databases, and free/inexpensive LLM APIs.

## Project Goals

- Explore different RAG implementations
- Compare retrieval quality from FAISS, Qdrant, etc.
- Evaluate performance across models like OpenAI, Together AI (Mistral, Mixtral), Cohere, Claude, and more
- Build production-style RAG workflows with minimal resources

## Features

- Vector search with Qdrant
- Embeddings via Sentence Transformers
- Prompt-based generation with Together AI, OpenAI, etc.
- Context injection and augmentation
- Styled terminal output using `rich`

## Planned Extensions

Gradio/Streamlit UI

LangChain comparison

Hybrid retrieval (keyword + dense)

Document chunking + QA
